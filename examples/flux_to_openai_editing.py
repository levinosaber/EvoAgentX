## Fluxç”Ÿæˆå›¾ç‰‡ + OpenAIæ·»åŠ æ–‡å­—

import os 
from dotenv import load_dotenv
from PIL import Image
import base64

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_ORGANIZATION_ID = os.getenv("OPENAI_ORGANIZATION_ID")
BFL_API_KEY = os.getenv("BFL_API_KEY")

if not all([OPENAI_API_KEY, OPENAI_ORGANIZATION_ID, BFL_API_KEY]):
    print("è¯·è®¾ç½®OPENAI_API_KEYã€OPENAI_ORGANIZATION_IDå’ŒBFL_API_KEYç¯å¢ƒå˜é‡")
    exit(1)

class FluxToOpenAITextTool:
    """Fluxç”Ÿæˆå›¾ç‰‡ + OpenAIæ·»åŠ æ–‡å­—çš„ç»„åˆå·¥å…·"""
    
    def __init__(self, flux_api_key: str, openai_api_key: str, openai_org_id: str, save_path: str = "./flux_openai_text_images"):
        self.flux_api_key = flux_api_key
        self.openai_api_key = openai_api_key
        self.openai_org_id = openai_org_id
        self.save_path = save_path
        os.makedirs(save_path, exist_ok=True)
        
    def generate_with_flux(self, prompt: str) -> str:
        """ä½¿ç”¨Fluxç”Ÿæˆå›¾ç‰‡"""
        from evoagentx.tools.flux_image_generation import FluxImageGenerationTool
        
        flux_tool = FluxImageGenerationTool(api_key=self.flux_api_key, save_path=self.save_path)
        result = flux_tool(prompt=prompt)
        generated_image_path = result.get("file_path")
        
        if not generated_image_path or not os.path.exists(generated_image_path):
            raise Exception("Fluxå›¾ç‰‡ç”Ÿæˆå¤±è´¥")
            
        print(f"Fluxç”Ÿæˆçš„å›¾ç‰‡å·²ä¿å­˜åˆ°: {generated_image_path}")
        return generated_image_path
    
    def add_text_with_openai(self, image_path: str, text_prompt: str, output_name: str = None) -> str:
        """ä½¿ç”¨OpenAIåœ¨å›¾ç‰‡ä¸Šæ·»åŠ æ–‡å­—"""
        from openai import OpenAI
        
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"è¾“å…¥å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        
        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        client = OpenAI(api_key=self.openai_api_key, organization=self.openai_org_id)
        
        # ç¼–è¾‘å›¾ç‰‡ï¼ˆä½¿ç”¨ gpt-image-1 æ¨¡å‹ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        response = client.images.edit(
            model="gpt-image-1",
            image=open(image_path, "rb"),
            prompt=text_prompt
        )
        
        # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
        output_name = output_name or "image_with_text.jpeg"
        if not output_name.lower().endswith((".png", ".jpg", ".jpeg", ".webp")):
            output_name += ".jpeg"
        
        edited_image_path = os.path.join(self.save_path, output_name)
        
        # ä¿å­˜ç¼–è¾‘åçš„å›¾ç‰‡
        image_base64 = response.data[0].b64_json
        image_bytes = base64.b64decode(image_base64)
        
        with open(edited_image_path, "wb") as f:
            f.write(image_bytes)
        
        print(f"âœ… OpenAIæ·»åŠ æ–‡å­—å®Œæˆï¼ä¿å­˜åœ¨: {edited_image_path}")
        return edited_image_path
    
    def _resize_to_square(self, image_path: str, size: int = 1024) -> str:
        """å°†å›¾ç‰‡è°ƒæ•´ä¸ºæ­£æ–¹å½¢"""
        with Image.open(image_path) as img:
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            width, height = img.size
            if width > height:
                new_width = size
                new_height = int(height * size / width)
            else:
                new_height = size
                new_width = int(width * size / height)
            
            img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            square_img = Image.new('RGB', (size, size), (255, 255, 255))
            
            x_offset = (size - new_width) // 2
            y_offset = (size - new_height) // 2
            square_img.paste(img_resized, (x_offset, y_offset))
            
            temp_path = image_path.replace('.', '_square.')
            square_img.save(temp_path, format='PNG')
            return temp_path
    
    def generate_and_add_text(self, generation_prompt: str, text_prompt: str, output_name: str = None) -> dict:
        """å®Œæ•´çš„ç”Ÿæˆ+æ·»åŠ æ–‡å­—æµç¨‹"""
        print(f"å¼€å§‹ç”Ÿæˆå›¾ç‰‡: {generation_prompt}")
        generated_image_path = self.generate_with_flux(generation_prompt)
        
        print(f"å¼€å§‹æ·»åŠ æ–‡å­—: {text_prompt}")
        edited_image_path = self.add_text_with_openai(
            image_path=generated_image_path,
            text_prompt=text_prompt,
            output_name=output_name
        )
        
        return {
            "generated_image_path": generated_image_path,
            "edited_image_path": edited_image_path,
            "generation_prompt": generation_prompt,
            "text_prompt": text_prompt
        }

def example():
    """ç®€å•ç¤ºä¾‹ - Fluxè‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡åœ°å€ï¼Œç”¨æˆ·åªéœ€æŒ‡å®šæœ€ç»ˆä¿å­˜åœ°å€"""
    tool = FluxToOpenAITextTool(
        flux_api_key=BFL_API_KEY,
        openai_api_key=OPENAI_API_KEY,
        openai_org_id=OPENAI_ORGANIZATION_ID
    )
    
    # ç”¨æˆ·åªéœ€è¦æŒ‡å®šæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡åœ°å€
    final_output_name = "my_final_landscape.jpeg"
    
    result = tool.generate_and_add_text(
        generation_prompt="ç”Ÿæˆä¸€å‰¯é©¬è€³ä»–çš„é£æ™¯ç…§ï¼ŒåŒ…æ‹¬é©¬è€³ä»–é¦–ä»˜mostaå’Œæµ·å²¸é£å…‰",
        text_prompt="åœ¨å›¾ç‰‡ä¸Šæ·»åŠ ç®€ä½“ä¸­æ–‡å¹¿å‘Šæ ‡è¯­ï¼Œâ€˜é©¬è€³ä»–ï¼Œåœ°ä¸­æµ·çš„æ˜ç â€™ï¼Œè‰ºæœ¯é£æ ¼çš„å­—ä½“ï¼Œå¹¿å‘Šé£æ ¼",
        output_name=final_output_name  # åªæŒ‡å®šæœ€ç»ˆä¿å­˜çš„å›¾ç‰‡åç§°
    )
    
    print(f"\nğŸ‰ å·¥ä½œæµå®Œæˆï¼")
    print(f"ğŸ“ Fluxç”Ÿæˆçš„åŸå§‹å›¾ç‰‡: {result['generated_image_path']}")
    print(f"ğŸ“ æœ€ç»ˆä¿å­˜çš„å›¾ç‰‡: {result['edited_image_path']}")
    print(f"ğŸ¨ ç”Ÿæˆæç¤º: {result['generation_prompt']}")
    print(f"âœï¸ æ–‡å­—æç¤º: {result['text_prompt']}")

def openai_example():
    """ç®€å•çš„ OpenAI å›¾ç‰‡ç¼–è¾‘ç¤ºä¾‹ - ç¼–è¾‘ flux_42_1.jpeg"""
    from openai import OpenAI
    
    # è¾“å…¥å›¾ç‰‡è·¯å¾„
    image_path = "flux_openai_text_images/flux_42_1.jpeg"
    
    # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        print(f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
        return
    
    # åˆ›å»º OpenAI å®¢æˆ·ç«¯
    client = OpenAI(api_key=OPENAI_API_KEY, organization=OPENAI_ORGANIZATION_ID)
    
    # ç¼–è¾‘å›¾ç‰‡ï¼ˆç®€åŒ–å‚æ•°ï¼‰
    response = client.images.edit(
        model="gpt-image-1",
        image=open(image_path, "rb"),
        prompt="åœ¨å›¾ç‰‡é¡¶éƒ¨ä¸­å¤®æ·»åŠ ç™½è‰²æ–‡å­—'AI Generated Art - 2024'ï¼Œå­—ä½“è¦å¤§ä¸”æ¸…æ™°å¯è§"
    )
    
    # ä¿å­˜ç¼–è¾‘åçš„å›¾ç‰‡
    output_path = "flux_openai_text_images/flux_42_1_edited.jpeg"
    image_base64 = response.data[0].b64_json
    image_bytes = base64.b64decode(image_base64)
    
    with open(output_path, "wb") as f:
        f.write(image_bytes)
    
    print(f"âœ… å›¾ç‰‡ç¼–è¾‘å®Œæˆï¼ä¿å­˜åœ¨: {output_path}")

if __name__ == "__main__":
    example()  # æ³¨é‡Šæ‰åŸæ¥çš„ç¤ºä¾‹
    # openai_example()  # è¿è¡Œæ–°çš„ OpenAI ç¼–è¾‘ç¤ºä¾‹ 